{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad99f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.yolo_inference import yolo_infer2\n",
    "from lib.emotic import Emotic\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22da3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the categories\n",
    "# our model outputs numbers as categories, so we much have a mapping from the numbers to the emotions\n",
    "cat = ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion', 'Confidence', 'Disapproval', 'Disconnection', \\\n",
    "          'Disquietment', 'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem', 'Excitement', 'Fatigue', 'Fear','Happiness', \\\n",
    "          'Pain', 'Peace', 'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise', 'Sympathy', 'Yearning']\n",
    "cat2ind = {}\n",
    "ind2cat = {}\n",
    "for idx, emotion in enumerate(cat):\n",
    "    cat2ind[emotion] = idx\n",
    "    ind2cat[idx] = emotion\n",
    "\n",
    "vad = ['Valence', 'Arousal', 'Dominance']\n",
    "ind2vad = {}\n",
    "for idx, continuous in enumerate(vad):\n",
    "    ind2vad[idx] = continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89538f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to normalise the demo image using the statistics of the training data the model was trained on\n",
    "context_mean = [0.4690646, 0.4407227, 0.40508908]\n",
    "context_std = [0.2514227, 0.24312855, 0.24266963]\n",
    "body_mean = [0.43832874, 0.3964344, 0.3706214]\n",
    "body_std = [0.24784276, 0.23621225, 0.2323653]\n",
    "context_norm = [context_mean, context_std]\n",
    "body_norm = [body_mean, body_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c8e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640) # set Width\n",
    "cap.set(4,480) # set Height\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1) # Flip camera horizontally\n",
    "    \n",
    "    xs, _, r = yolo_infer2(frame, 'experiment/results/',\n",
    "            'experiment/models/', context_norm, body_norm, ind2cat, ind2vad, write_op=False, return_op=True)\n",
    "\n",
    "    # For reversing the operation:\n",
    "    im_np = np.asarray(r)\n",
    "    im_np = cv2.cvtColor(im_np, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    cv2.imshow('frame', im_np)\n",
    "    # print(xs['bbox_0']['cat'][1])\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: # press 'ESC' to quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
